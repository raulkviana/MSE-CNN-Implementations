<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.9.7" xml:lang="en-US">
  <compounddef id="mainpage_8md" kind="file" language="Markdown">
    <compoundname>mainpage.md</compoundname>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
    </detaileddescription>
    <programlisting>
<codeline></codeline>
<codeline></codeline>
<codeline><highlight class="normal">#<sp/>MSE-CNN<sp/>Implementation</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">&lt;div<sp/>align=&quot;center&quot;&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;img<sp/>src=&quot;../../imgs/msecnn_model.png&quot;<sp/>width=800<sp/>/&gt;</highlight></codeline>
<codeline><highlight class="normal">&lt;/div&gt;</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">Code<sp/>database<sp/>with<sp/>an<sp/>implementation<sp/>of<sp/>MSE-CNN<sp/>[1].<sp/>Besides<sp/>the<sp/>code,<sp/>the<sp/>dataset<sp/>and<sp/>coefficients<sp/>obtained<sp/>after<sp/>training<sp/>are<sp/>provided.</highlight></codeline>
<codeline></codeline>
<codeline></codeline>
<codeline><highlight class="normal">```python</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>import<sp/>torch</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>import<sp/>MSECNN</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>import<sp/>train_model_utils</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>#<sp/>Initialize<sp/>parameters</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>path_to_folder_with_model_params<sp/>=<sp/>&quot;model_coefficients/best_coefficients&quot;</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>device<sp/>=<sp/>&quot;cuda:0&quot;</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>qp<sp/>=<sp/>32<sp/><sp/>#<sp/>Quantisation<sp/>Parameter</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/></highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>#<sp/>Initialize<sp/>Model</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>stg1_2<sp/>=<sp/>msecnn.MseCnnStg1(device=device,<sp/>QP=qp).to(device)</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>stg3<sp/>=<sp/>msecnn.MseCnnStgX(device=device,<sp/>QP=qp).to(device)</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>stg4<sp/>=<sp/>msecnn.MseCnnStgX(device=device,<sp/>QP=qp).to(device)</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>stg5<sp/>=<sp/>msecnn.MseCnnStgX(device=device,<sp/>QP=qp).to(device)</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>stg6<sp/>=<sp/>msecnn.MseCnnStgX(device=device,<sp/>QP=qp).to(device)</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>model<sp/>=<sp/>(stg1_2,<sp/>stg3,<sp/>stg4,<sp/>stg5,<sp/>stg6)</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>model<sp/>=<sp/>train_model_utils.load_model_parameters_eval(model,<sp/>path_to_folder_with_model_params,<sp/>device)</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>#<sp/>Loss<sp/>function</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>loss_fn<sp/>=<sp/>msecnn.LossFunctionMSE()</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/></highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>#<sp/>Path<sp/>to<sp/>labels</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>l_path_val<sp/>=<sp/>&quot;example_data/stg2&quot;</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>#<sp/>Random<sp/>CTU<sp/>and<sp/>labels</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>CTU<sp/>=<sp/>torch.rand(1,<sp/>1,<sp/>128,<sp/>128).to(device)</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>CTU</highlight></codeline>
<codeline><highlight class="normal">tensor([[[[0.9320,<sp/>0.6777,<sp/>0.4490,<sp/><sp/>...,<sp/>0.0413,<sp/>0.6278,<sp/>0.5375],</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>[0.3544,<sp/>0.5620,<sp/>0.8339,<sp/><sp/>...,<sp/>0.6420,<sp/>0.2527,<sp/>0.3104],</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>[0.0555,<sp/>0.4991,<sp/>0.9972,<sp/><sp/>...,<sp/>0.3898,<sp/>0.1169,<sp/>0.1661],</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>...,</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>[0.9452,<sp/>0.3566,<sp/>0.9825,<sp/><sp/>...,<sp/>0.3941,<sp/>0.7534,<sp/>0.8656],</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>[0.3839,<sp/>0.8459,<sp/>0.4369,<sp/><sp/>...,<sp/>0.9569,<sp/>0.2609,<sp/>0.6421],</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>[0.1734,<sp/>0.7182,<sp/>0.8074,<sp/><sp/>...,<sp/>0.2122,<sp/>0.7573,<sp/>0.2492]]]])</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>cu_pos<sp/>=<sp/>torch.tensor([[0,<sp/>0]]).to(device)</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>cu_size<sp/>=<sp/>torch.tensor([[64,<sp/>64]]).to(device)<sp/><sp/>#<sp/>Size<sp/>of<sp/>the<sp/>CU<sp/>of<sp/>the<sp/>second<sp/>stage</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>split_label<sp/>=<sp/>torch.tensor([[1]]).to(device)</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>RDs<sp/>=<sp/>torch.rand(1,<sp/>6).to(device)<sp/>*<sp/>10_000</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>RDs</highlight></codeline>
<codeline><highlight class="normal">tensor([[1975.6646,<sp/>2206.7600,<sp/>1570.3577,<sp/>3570.9478,<sp/>6728.2612,<sp/><sp/>527.9994]])</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>#<sp/>Compute<sp/>prediction<sp/>for<sp/>stages<sp/>1<sp/>and<sp/>2</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>#<sp/>Stage<sp/>1<sp/>and<sp/>2</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>pred1_2,<sp/>CUs,<sp/>ap<sp/>=<sp/>model[0](CTU,<sp/>cu_size,<sp/>cu_pos)<sp/><sp/>#<sp/>Pass<sp/>CU<sp/>through<sp/>network</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>pred1_2</highlight></codeline>
<codeline><highlight class="normal">tensor([[9.9982e-01,<sp/>1.8124e-04,<sp/>9.9010e-21,<sp/>5.9963e-29,<sp/>1.9118e-24,<sp/>1.0236e-25]],</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/>grad_fn=&lt;SoftmaxBackward0&gt;)</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>CUs.shape</highlight></codeline>
<codeline><highlight class="normal">torch.Size([1,<sp/>16,<sp/>64,<sp/>64])</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/></highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>#<sp/>Compute<sp/>the<sp/>loss</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;&gt;<sp/>loss,<sp/>loss_CE,<sp/>loss_RD<sp/>=<sp/>loss_fn(pred1_2,<sp/>split_label,<sp/>RDs)</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;<sp/>loss</highlight></codeline>
<codeline><highlight class="normal">tensor(177.1340,<sp/>grad_fn=&lt;AddBackward0&gt;)</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;<sp/>loss_CE</highlight></codeline>
<codeline><highlight class="normal">tensor(174.3921,<sp/>grad_fn=&lt;NegBackward0&gt;)</highlight></codeline>
<codeline><highlight class="normal">&gt;&gt;<sp/>loss_RD</highlight></codeline>
<codeline><highlight class="normal">tensor(2.7419,<sp/>grad_fn=&lt;MeanBackward1&gt;)</highlight></codeline>
<codeline><highlight class="normal">```</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">-<sp/>[MSE-CNN<sp/>Implementation](#mse-cnn-implementation)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>-<sp/>[1.<sp/>Introduction](#1-introduction)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>-<sp/>[2.<sp/>Theorectical<sp/>Background](#2-theorectical-background)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>-<sp/>[2.1<sp/>Partitioning<sp/>in<sp/>VVC](#21-partitioning-in-vvc)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>-<sp/>[2.2<sp/>MSE-CNN](#22-mse-cnn)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>[2.2.1<sp/>Architecture](#221-architecture)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>[2.2.2<sp/>Loss<sp/>Function](#222-loss-function)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>[2.2.3<sp/>Training](#223-training)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>[2.2.4<sp/>Implementation<sp/>remarks](#224-implementation-remarks)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>-<sp/>[3.<sp/>Dataset](#3-dataset)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>-<sp/>[4.<sp/>Results](#4-results)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>-<sp/>[4.1<sp/>F1-score,<sp/>Recall<sp/>and<sp/>Precision<sp/>with<sp/>test<sp/>data](#41-f1-score-recall-and-precision-with-test-data)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>-<sp/>[4.2<sp/>Confusion<sp/>matrices](#42-confusion-matrices)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>[4.2.1<sp/>Stages<sp/>2<sp/>and<sp/>3](#421-stages-2-and-3)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>[4.2.2<sp/>Stages<sp/>4<sp/>and<sp/>5](#422-stages-4-and-5)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>[4.2.3<sp/>Stage<sp/>6](#423-stage-6)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>-<sp/>[4.3<sp/>Y-PSNR,<sp/>Complexity<sp/>Reduction<sp/>and<sp/>Bitrate<sp/>with<sp/>test<sp/>data](#43-y-psnr-complexity-reduction-and-bitrate-with-test-data)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>-<sp/>[5.<sp/>Relevant<sp/>Folders<sp/>and<sp/>files](#5-relevant-folders-and-files)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>-<sp/>[5.1<sp/>Folders](#51-folders)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>-<sp/>[5.2<sp/>Files<sp/>in<sp/>src<sp/>folder](#52-files-in-src-folder)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>-<sp/>[6.<sp/>Installation<sp/>of<sp/>dependencies](#6-installation-of-dependencies)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>-<sp/>[Requirements](#requirements)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>-<sp/>[Package<sp/>Distributions](#package-distributions)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>-<sp/>[7.<sp/>Contributions](#7-contributions)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>-<sp/>[8.<sp/>License](#8-license)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>-<sp/>[9.<sp/>TODO](#9-todo)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>-<sp/>[10.<sp/>References](#10-references)</highlight></codeline>
<codeline></codeline>
<codeline></codeline>
<codeline><highlight class="normal">##<sp/>1.<sp/>Introduction</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">The<sp/>emergence<sp/>of<sp/>new<sp/>technologies<sp/>that<sp/>provide<sp/>creative<sp/>audiovisual<sp/>experiences,<sp/>such<sp/>as<sp/>360-degree<sp/>films,<sp/>virtual<sp/>reality,<sp/>augmented<sp/>reality,<sp/>4K,<sp/>8K<sp/>UHD,<sp/>16K,<sp/>and<sp/>also<sp/>with<sp/>the<sp/>rise<sp/>of<sp/>video<sp/>traffic<sp/>on<sp/>the<sp/>web,<sp/>shows<sp/>the<sp/>current<sp/>demand<sp/>for<sp/>video<sp/>data<sp/>in<sp/>the<sp/>modern<sp/>world.<sp/>Because<sp/>of<sp/>this<sp/>tension,<sp/>Versatile<sp/>Video<sp/>Coding<sp/>(VVC)<sp/>was<sp/>developed<sp/>due<sp/>to<sp/>the<sp/>the<sp/>necessity<sp/>for<sp/>the<sp/>introduction<sp/>of<sp/>new<sp/>coding<sp/>standards.<sp/>Despite<sp/>the<sp/>advancements<sp/>achieved<sp/>with<sp/>the<sp/>introduction<sp/>of<sp/>this<sp/>standard,<sp/>its<sp/>complexity<sp/>has<sp/>increased<sp/>very<sp/>much.<sp/>The<sp/>new<sp/>partitioning<sp/>technique<sp/>is<sp/>responsible<sp/>for<sp/>majority<sp/>of<sp/>the<sp/>increase<sp/>in<sp/>encoding<sp/>time.<sp/>This<sp/>extended<sp/>duration<sp/>is<sp/>linked<sp/>with<sp/>the<sp/>optimization<sp/>of<sp/>the<sp/>Rate-Distortion<sp/>cost<sp/>(RD<sp/>cost).<sp/>Although<sp/>VVC<sp/>offers<sp/>higher<sp/>compression<sp/>rates,<sp/>the<sp/>complexity<sp/>of<sp/>its<sp/>encoding<sp/>is<sp/>high.</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">&lt;div<sp/>align=&quot;center&quot;&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;img<sp/>src=&quot;../../imgs/funny_memes_about_this_work/72rrr9.jpg&quot;<sp/>width=300<sp/>/&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;p&gt;Fig.<sp/>1:<sp/>VVC<sp/>Complexity&lt;/p&gt;</highlight></codeline>
<codeline><highlight class="normal">&lt;/div&gt;</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">In<sp/>light<sp/>of<sp/>this,<sp/>the<sp/>Multi-Stage<sp/>Exit<sp/>Convolutional<sp/></highlight></codeline>
<codeline><highlight class="normal">Neural<sp/>Nework<sp/>(MSE-CNN)<sp/>was<sp/>developed.<sp/>This<sp/>Deep<sp/>Learning-based<sp/>model<sp/>is<sp/>organised<sp/>in<sp/>a<sp/>sequential<sp/>structure<sp/>with<sp/>several<sp/>stages.<sp/>Each<sp/>stage,<sp/>which<sp/>represents<sp/>a<sp/>different<sp/>partition<sp/>depth,<sp/>encompasses<sp/>a<sp/>set<sp/>of<sp/>layers<sp/>for<sp/>extracting<sp/>features<sp/>from<sp/>a<sp/>Coding<sp/>Tree<sp/>Unit<sp/>(CTU)<sp/>and<sp/>deciding<sp/>how<sp/>to<sp/>partition<sp/>it.<sp/>Instead<sp/>of<sp/>using<sp/>recursive<sp/>approaches<sp/>to<sp/>determine<sp/>the<sp/>optimal<sp/>way<sp/>to<sp/>fragment<sp/>an<sp/>image,<sp/>this<sp/>model<sp/>allows<sp/>VVC<sp/>to<sp/>estimate<sp/>the<sp/>most<sp/>appropriate<sp/>way<sp/>of<sp/>doing<sp/>it.<sp/>**This<sp/>work<sp/>presents<sp/>a<sp/>model<sp/>of<sp/>the<sp/>MSE-CNN<sp/>that<sp/>employs<sp/>training<sp/>procedures<sp/>distinct<sp/>from<sp/>the<sp/>original<sp/>implementation<sp/>of<sp/>this<sp/>network,<sp/>as<sp/>well<sp/>as<sp/>the<sp/>ground-thruth<sp/>to<sp/>train<sp/>and<sp/>validate<sp/>the<sp/>model<sp/>and<sp/>an<sp/>interpretation<sp/>of<sp/>the<sp/>work<sp/>done<sp/>by<sp/>the<sp/>MSE-CNN’s<sp/>original<sp/>creators**.</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">&lt;div<sp/>align=&quot;center&quot;&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;img<sp/>src=&quot;../../imgs/funny_memes_about_this_work/72roie.jpg&quot;<sp/>width=400<sp/>/&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;p&gt;Fig.<sp/>2:<sp/>MSE-CNN<sp/>benefits&lt;/p&gt;</highlight></codeline>
<codeline><highlight class="normal">&lt;/div&gt;</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">##<sp/>2.<sp/>Theorectical<sp/>Background</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">###<sp/>2.1<sp/>Partitioning<sp/>in<sp/>VVC</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">The<sp/>key<sp/>objective<sp/>of<sp/>partitioning<sp/>is<sp/>to<sp/>divide<sp/>frames<sp/>into<sp/>pieces<sp/>in<sp/>a<sp/>way<sp/>that<sp/>results<sp/>in<sp/>a</highlight></codeline>
<codeline><highlight class="normal">reduction<sp/>of<sp/>the<sp/>RD<sp/>cost.<sp/>To<sp/>achieve<sp/>a<sp/>perfect<sp/>balance<sp/>of<sp/>quality<sp/>and<sp/>bitrate,<sp/>numerous<sp/>image</highlight></codeline>
<codeline><highlight class="normal">fragments<sp/>combinations<sp/>must<sp/>be<sp/>tested,<sp/>which<sp/>is<sp/>computationally<sp/>expensive.<sp/>Due<sp/>to<sp/>the<sp/>intensive</highlight></codeline>
<codeline><highlight class="normal">nature<sp/>of<sp/>this<sp/>process,<sp/>a<sp/>high<sp/>compression<sp/>rate<sp/>can<sp/>be<sp/>attained.<sp/>Partitioning<sp/>contributes<sp/>heavily</highlight></codeline>
<codeline><highlight class="normal">to<sp/>both<sp/>the<sp/>complexity<sp/>and<sp/>compression<sp/>gains<sp/>in<sp/>VVC.<sp/>H.266<sp/>(VVC),<sp/>organize<sp/>a<sp/>video<sp/>sequence<sp/>in<sp/>many<sp/>frames<sp/>that<sp/>are<sp/>divided<sp/>into<sp/>smaller<sp/>pieces.<sp/>First,<sp/>pictures<sp/>are<sp/>split<sp/>into<sp/>coding<sp/>tree<sp/>units<sp/>(CTUs),<sp/>and<sp/>then<sp/>they<sp/>are<sp/>divided<sp/>into<sp/>coding<sp/>units<sp/>(CUs).<sp/>For<sp/>the<sp/>luma<sp/>channel,<sp/>the<sp/>largest<sp/>CTU<sp/>size<sp/>in</highlight></codeline>
<codeline><highlight class="normal">VVC<sp/>is<sp/>128x128<sp/>and<sp/>the<sp/>smallest<sp/>is<sp/>4x4.<sp/>In<sp/>VVC,<sp/>a<sp/>quad-tree<sp/>(QT)<sp/>is<sp/>initially<sp/>applied<sp/>to<sp/>the<sp/>CTUs<sp/>in<sp/>the<sp/>first<sp/>level,<sp/>and<sp/>then<sp/>a<sp/>quad-tree<sp/>with<sp/>nested<sp/>multi-type<sp/>tree<sp/>(QMTT)<sp/>is<sp/>applied<sp/>recursively.<sp/></highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">&lt;div<sp/>align=&quot;center&quot;&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;img<sp/>src=&quot;../../imgs/vvc_parti_real.png&quot;<sp/>/&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;p&gt;Fig.<sp/>3:<sp/>Types<sp/>of<sp/>partitions<sp/>in<sp/>VVC&lt;/p&gt;</highlight></codeline>
<codeline><highlight class="normal">&lt;/div&gt;</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">This<sp/>innovation<sp/>makes<sp/>it<sp/>possible<sp/>to<sp/>split<sp/>CUs<sp/>in<sp/>different<sp/>rectangle<sp/>forms.<sp/>Splitting<sp/>a<sp/>CU<sp/>into:</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">*<sp/>three<sp/>rectangles<sp/>with<sp/>a<sp/>ratio<sp/>of<sp/>1:2:1<sp/>results<sp/>in<sp/>a<sp/>ternary<sp/>tree<sp/>(TT),<sp/>with<sp/>the<sp/>center<sp/>rectangle<sp/>being<sp/>half<sp/>the<sp/>size<sp/>of<sp/>the<sp/>original<sp/>CU;<sp/>when<sp/>applied<sp/>horizontally<sp/>it<sp/>is<sp/>called<sp/>a<sp/>horizontal<sp/>ternary<sp/>tree<sp/>(HTT),<sp/>and<sp/>vertical<sp/>ternary<sp/>tree<sp/>(VTT)<sp/>when<sp/>it<sp/>is<sp/>done<sp/>vertically.<sp/></highlight></codeline>
<codeline><highlight class="normal">*<sp/>two<sp/>rectangles<sp/>results<sp/>in<sp/>a<sp/>binary<sp/>tree<sp/>(BT)partition,<sp/>a<sp/>block<sp/>with<sp/>two<sp/>symmetrical<sp/>structures;<sp/>like<sp/>in<sp/>the<sp/>case<sp/>of<sp/>the<sp/>TT,<sp/>depending<sp/>on<sp/>the<sp/>way<sp/>the<sp/>split<sp/>is<sp/>done,<sp/>it<sp/>can<sp/>be<sp/>called<sp/>either</highlight></codeline>
<codeline><highlight class="normal">a<sp/>vertical<sp/>binary<sp/>tree<sp/>(VBT)<sp/>or<sp/>a<sp/>horizontal<sp/>binary<sp/>tree<sp/>(HBT).</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">The<sp/>association<sp/>of<sp/>BT<sp/>and<sp/>TT<sp/>is<sp/>named<sp/>a<sp/>multi-type<sp/>tree<sp/>(MTT).<sp/>The<sp/>introduction<sp/>of<sp/>BT<sp/>and<sp/>TT<sp/>partitions<sp/>enables<sp/>the<sp/>creation<sp/>of<sp/>various<sp/>new<sp/>types<sp/>of<sp/>forms,<sp/>with<sp/>heights<sp/>and<sp/>widths<sp/>that<sp/>can<sp/>be<sp/>a<sp/>combination<sp/>between<sp/>128,<sp/>64,<sp/>32,<sp/>16,<sp/>8<sp/>and<sp/>4.<sp/>The<sp/>increased<sp/>number<sp/>of<sp/>possible<sp/>CUs<sp/>boosts<sp/>the<sp/>ability<sp/>of<sp/>the<sp/>codec<sp/>to<sp/>fragment</highlight></codeline>
<codeline><highlight class="normal">an<sp/>image<sp/>more<sp/>efficiently,<sp/>allowing<sp/>better<sp/>predictions<sp/>and<sp/>higher<sp/>compressing<sp/>abilities.<sp/>Although<sp/>this<sp/>standard<sp/>now<sp/>have<sp/>these<sp/>advantages,<sp/>as<sp/>a<sp/>downside<sp/>it<sp/>takes<sp/>longer<sp/>to<sp/>encode.</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">&lt;div<sp/>align=&quot;center&quot;&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;img<sp/>src=&quot;../../imgs/partitioning_image.png&quot;<sp/>/&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;p&gt;Fig.<sp/>4:<sp/>Partitioning<sp/>in<sp/>VVC&lt;/p&gt;</highlight></codeline>
<codeline><highlight class="normal">&lt;/div&gt;</highlight></codeline>
<codeline></codeline>
<codeline></codeline>
<codeline><highlight class="normal">###<sp/>2.2<sp/>MSE-CNN</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">Multi-Stage<sp/>Exit<sp/>Convolutional<sp/>Neural<sp/>Network<sp/>(MSE-CNN)<sp/>is<sp/>a<sp/>DL<sp/>model<sp/>that<sp/>seeks<sp/>to<sp/>forecast<sp/>CUs<sp/>in<sp/>a<sp/>waterfall<sp/>architecture<sp/>(top-down<sp/>manner),<sp/>it<sp/>integrates<sp/>.<sp/>This<sp/>structure<sp/>takes<sp/>a<sp/>CTU<sp/>as<sp/>input,<sp/>extracts<sp/>features<sp/>from<sp/>it,<sp/>splits<sp/>the<sp/>CU<sp/>into<sp/>one<sp/>of<sp/>at<sp/>most<sp/>six<sp/>possible<sp/>partitions<sp/>(Non-split,<sp/>QT,<sp/>HBT,<sp/>VBT,<sp/>HTT,<sp/>and<sp/>VTT),<sp/>and<sp/>then<sp/>sends<sp/>it<sp/>to<sp/>the<sp/>next<sp/>stage.<sp/>This<sp/>model<sp/>has<sp/>CTUs<sp/>as<sp/>inputs<sp/>in<sp/>the<sp/>first<sp/>stage,<sp/>either<sp/>in<sp/>the<sp/>chroma<sp/>or<sp/>luma<sp/>channel,<sp/>and<sp/>feature<sp/>maps<sp/>in<sp/>the<sp/>subsequent<sp/>stages.<sp/>Furthermore,<sp/>it<sp/>generates<sp/>feature<sp/>maps<sp/>and<sp/>a<sp/>split<sp/>decision<sp/>at<sp/>each<sp/>level.<sp/>In<sp/>the<sp/>event<sp/>that<sp/>one<sp/>of<sp/>the<sp/>models<sp/>returns<sp/>the<sp/>split<sp/>decision<sp/>as<sp/>Non-Split,<sp/>the<sp/>partitioning<sp/>of<sp/>the<sp/>CU<sp/>is<sp/>ended<sp/>immediately.</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">**Note**:<sp/>Details<sp/>about<sp/>how<sp/>to<sp/>load<sp/>model<sp/>coefficients<sp/>can<sp/>be<sp/>found<sp/>[here](modelcoefpage.md).</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">####<sp/>2.2.1<sp/>Architecture</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">This<sp/>model<sp/>is<sp/>composed<sp/>by<sp/>the<sp/>following<sp/>blocks:</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">*<sp/>Initially,<sp/>this<sp/>model<sp/>adds<sp/>more<sp/>channels<sp/>to<sp/>the<sp/>input<sp/>of<sp/>this<sp/>network<sp/>to<sp/>create<sp/>more<sp/>features</highlight></codeline>
<codeline><highlight class="normal">from<sp/>it;<sp/>this<sp/>is<sp/>accomplished<sp/>by<sp/>utilising<sp/>simple<sp/>convolutional<sp/>layers.<sp/></highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">&lt;div<sp/>align=&quot;center&quot;&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;img<sp/>src=&quot;../../imgs/over_con_block.drawio.png&quot;<sp/>/&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;p&gt;Fig.<sp/>5:<sp/>Overlapping<sp/>convolution<sp/>layer&lt;/p&gt;</highlight></codeline>
<codeline><highlight class="normal">&lt;/div&gt;</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">*<sp/>To<sp/>extract<sp/>more<sp/>characteristics<sp/>from<sp/>the<sp/>data,<sp/>the<sp/>information<sp/>is<sp/>then<sp/>passed<sp/>through<sp/>a<sp/>series<sp/>of<sp/>convolutional<sp/>layers;<sp/>these<sp/>layers<sp/>were<sp/>named<sp/>Conditional<sp/>Convolution.<sp/></highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/></highlight></codeline>
<codeline><highlight class="normal">&lt;div<sp/>align=&quot;center&quot;&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;img<sp/>src=&quot;../../imgs/resnet_mse.png&quot;<sp/>/&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;p&gt;Fig.<sp/>6:<sp/>Conditional<sp/>Convolution&lt;/p&gt;</highlight></codeline>
<codeline><highlight class="normal">&lt;/div&gt;</highlight></codeline>
<codeline></codeline>
<codeline></codeline>
<codeline><highlight class="normal">*<sp/>At<sp/>the<sp/>end,<sp/>a<sp/>final<sp/>layer<sp/>is<sp/>employed<sp/>to<sp/>determine<sp/>the</highlight></codeline>
<codeline><highlight class="normal">optimal<sp/>manner<sp/>of<sp/>partitioning<sp/>the<sp/>CU.<sp/>This<sp/>layer<sp/>is<sp/>a<sp/>blend<sp/>of<sp/>fully<sp/>connected<sp/>and<sp/>convolutional</highlight></codeline>
<codeline><highlight class="normal">layers.</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">&lt;div<sp/>align=&quot;center&quot;&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;img<sp/>src=&quot;../../imgs/sub_networks.png&quot;<sp/>/&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;p&gt;Fig.<sp/>7:<sp/>Sub-networks&lt;/p&gt;</highlight></codeline>
<codeline><highlight class="normal">&lt;/div&gt;</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">&lt;span<sp/>style=&quot;text-decoration:<sp/>underline&quot;&gt;Note&lt;/span&gt;:<sp/>For<sp/>more<sp/>details<sp/>regarding<sp/>these<sp/>layers<sp/>check<sp/>[1]</highlight></codeline>
<codeline><highlight class="normal"><sp/></highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">####<sp/>2.2.2<sp/>Loss<sp/>Function</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">The<sp/>loss<sp/>developed<sp/>for<sp/>the<sp/>MSE-CNN<sp/>is<sp/>the<sp/>result<sp/>of<sp/>two<sp/>other<sp/>functions,<sp/>as<sp/>defined<sp/>in<sp/>the</highlight></codeline>
<codeline><highlight class="normal">following<sp/>expression:</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">$$<sp/>L<sp/>=<sp/>L_{CE}+\beta<sp/>L_{RD}$$</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">In<sp/>the<sp/>above<sp/>equation,<sp/>$\beta$<sp/>is<sp/>a<sp/>real<sp/>number<sp/>to<sp/>adjust<sp/>the<sp/>influence<sp/>of<sp/>the<sp/>$L_{RD}$<sp/>loss.<sp/>The<sp/>first<sp/>member<sp/>of<sp/>this<sp/>loss<sp/>function<sp/>is<sp/>a<sp/>modified<sp/>Cross-Entrotopy<sp/>loss,<sp/>developed<sp/>to<sp/>solve<sp/>imbalanced<sp/>dataset<sp/>issues:</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">$$L_{CEmod}<sp/>=<sp/>-\frac{1}{N}\sum_{n=1}^N<sp/>\sum_{m\varepsilon<sp/>Partitions}(\frac{1}{p_m})^\alpha<sp/>y_{n,<sp/>m}\log(\hat{y}_{n,<sp/>m})$$</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">&lt;div<sp/>align=&quot;center&quot;&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;sub&gt;<sp/>Eq.<sp/>1:<sp/>In<sp/>this<sp/>equation<sp/>&quot;n&quot;<sp/>is<sp/>the<sp/>batch<sp/>number,<sp/>&quot;m&quot;<sp/>is<sp/>the<sp/>corresponding<sp/>partition<sp/>(0<sp/>(Non-Split),<sp/>1<sp/>(QT),<sp/>2<sp/>(HBT),<sp/>3<sp/>(VBT),<sp/>4<sp/>(VTT),<sp/>5<sp/>(HTT)),<sp/>&quot;N&quot;<sp/>is<sp/>the<sp/>total<sp/>number<sp/>of<sp/>batches<sp/>and<sp/>alpha<sp/>is<sp/>a<sp/>parameter<sp/>to<sp/>configure<sp/>the<sp/>penalties<sp/>for<sp/>the<sp/>less<sp/>represented<sp/>classes<sp/>&lt;/sub&gt;<sp/></highlight></codeline>
<codeline><highlight class="normal">&lt;/div&gt;</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">&lt;br&gt;</highlight></codeline>
<codeline><highlight class="normal">&lt;br&gt;</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">Concerning<sp/>the<sp/>second<sp/>member<sp/>of<sp/>the<sp/>MSE-CNN<sp/>loss<sp/>function,<sp/>this<sp/>constituent<sp/>gives<sp/>the<sp/>network<sp/>the<sp/>ability<sp/>to<sp/>also<sp/>make<sp/>predictions<sp/>based<sp/>on<sp/>the<sp/>RD<sp/>Cost.</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">$$L_{RD}<sp/>=<sp/>\frac{1}{N}\sum_{n=1}^N<sp/>\sum_{m\varepsilon<sp/>Partitions}\hat{y}_{n,<sp/>m}\frac{r_{n,<sp/>m}}{r_{n,<sp/>min}}-1$$</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">In<sp/>the<sp/>above<sp/>equation,<sp/>the<sp/>RD<sp/>costs<sp/>$r_{n,<sp/>m}$<sp/>uses<sp/>the<sp/>same<sp/>notation<sp/>for<sp/>&quot;n&quot;<sp/>and<sp/>&quot;m&quot;<sp/>as<sp/>the<sp/>previous<sp/>equation.<sp/>Regarding<sp/>$r_{n<sp/>,min}$,<sp/>it<sp/>is<sp/>the<sp/>minimal<sp/>RD<sp/>cost<sp/>for<sp/>the<sp/>nth<sp/>CU<sp/>among<sp/>all<sp/>split<sp/>modes<sp/>and<sp/></highlight></codeline>
<codeline><highlight class="normal">$$\frac{r_{n,<sp/>m}}{r_{n,<sp/>min}}<sp/>-<sp/>1$$</highlight></codeline>
<codeline><highlight class="normal">is<sp/>a<sp/>normalised<sp/>RD<sp/>cost.<sp/>As<sp/>a<sp/>relevant<sp/>note,<sp/>$r_{n,<sp/>min}$<sp/>is<sp/>equal<sp/>to<sp/>the<sp/>RD<sp/>cost<sp/>of<sp/>the<sp/>best<sp/>partition<sp/>mode.<sp/>Consequently,<sp/>the<sp/>result<sp/>of</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">&lt;div<sp/>align=&quot;center&quot;&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;img<sp/>src=&quot;../../imgs/formula.png&quot;<sp/>/&gt;</highlight></codeline>
<codeline><highlight class="normal">&lt;/div&gt;</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">ensures<sp/>that<sp/>CU&apos;s<sp/>partitions<sp/>with<sp/>greater<sp/>erroneously<sp/>predicted<sp/>probability<sp/>values<sp/>or<sp/>greater<sp/>RD<sp/>cost<sp/>values<sp/>$r_{n,<sp/>m}$<sp/>are<sp/>more<sp/>penalised.<sp/>In<sp/>$\frac{r_{n,<sp/>m}}{r_{n,<sp/>min}}<sp/>-<sp/>1$,<sp/>the<sp/>ideal<sp/>partition<sp/>has<sp/>a<sp/>normalised<sp/>RD<sp/>cost<sp/>of<sp/>zero,<sp/>but<sp/>the<sp/>other<sp/>partitions<sp/>do<sp/>not.<sp/>Therefore,<sp/>the<sp/>only<sp/>way<sp/>for<sp/>the<sp/>loss<sp/>to<sp/>equal<sp/>zero<sp/>is<sp/>if<sp/>the<sp/>probability<sp/>for<sp/>all<sp/>other<sp/>modes<sp/>also<sp/>equals<sp/>zero.<sp/>Consequently,<sp/>the<sp/>learning<sp/>algorithm<sp/>must<sp/>assign<sp/>a<sp/>greater<sp/>probability<sp/>to<sp/>the<sp/>optimal<sp/>split<sp/>mode<sp/>while<sp/>reducing<sp/>the<sp/>probabilities<sp/>for<sp/>the<sp/>rest.<sp/>**Experimentally<sp/>it<sp/>was<sp/>verified<sp/>that<sp/>this<sp/>function<sp/>wasn&apos;t<sp/>able<sp/>to<sp/>contribute<sp/>to<sp/>the<sp/>training<sp/>of<sp/>the<sp/>MSE-CNN,<sp/>this<sp/>contradicted<sp/>the<sp/>remarks<sp/>made<sp/>in<sp/>[1]**.</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">####<sp/>2.2.3<sp/>Training</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">The<sp/>strategy<sp/>used<sp/>to<sp/>train<sp/>the<sp/>MSE-CNN<sp/>was<sp/>very<sp/>similar<sp/>to<sp/>the<sp/>one<sp/>used<sp/>in<sp/>[1].<sp/>The<sp/>first<sp/>parts<sp/>of<sp/>the<sp/>model<sp/>to<sp/>be<sp/>trained<sp/>were<sp/>the<sp/>first<sp/>and<sp/>second<sp/>stages,<sp/>in<sp/>which<sp/>64x64<sp/>CUs<sp/>were<sp/>passed<sp/>through<sp/>the<sp/>second<sp/>depth.<sp/>Afterwards,<sp/>transfer<sp/>learning<sp/>was<sp/>used<sp/>to<sp/>pass<sp/>certain<sp/>coefficients<sp/>of<sp/>the<sp/>second<sp/>stage<sp/>to<sp/>the<sp/>third.<sp/>Then,<sp/>the<sp/>third<sp/>stage<sp/>was<sp/>trained<sp/>with<sp/>32x32<sp/>CUs<sp/>flowing<sp/>through<sp/>it.<sp/>After<sp/>this<sp/>step,<sp/>a<sp/>similar<sp/>process<sp/>was<sp/>done<sp/>to<sp/>the<sp/>following<sp/>stages.<sp/>It<sp/>is<sp/>worth<sp/>noting<sp/>that,<sp/>beginning<sp/>with<sp/>stage<sp/>4,<sp/>various<sp/>CUs<sp/>forms<sp/>are<sp/>at<sp/>the<sp/>models&apos;<sp/>input.<sp/>This<sp/>means<sp/>that<sp/>these<sp/>stages<sp/>were<sp/>fed<sp/>different<sp/>kinds<sp/>of<sp/>CUs.<sp/><sp/></highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">&lt;div<sp/>align=&quot;center&quot;&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;img<sp/>src=&quot;../../imgs/training_steps.png&quot;<sp/>width=300/&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;p&gt;Fig.<sp/>8:<sp/>Training<sp/>flow<sp/>used&lt;/p&gt;</highlight></codeline>
<codeline><highlight class="normal">&lt;/div&gt;</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">At<sp/>the<sp/>end<sp/>of<sp/>training,<sp/>6<sp/>models<sp/>were<sp/>obtained<sp/>one<sp/>for<sp/>each<sp/>partitioning<sp/>depth<sp/>in<sp/>the<sp/>luma<sp/>channel.<sp/>Although<sp/>models<sp/>for<sp/>the<sp/>luma<sp/>and<sp/>chroma<sp/>channels<sp/>could<sp/>be<sp/>created<sp/>for<sp/>all<sp/>the<sp/>shapes<sp/>of<sp/>CUs<sp/>that<sp/>are<sp/>possible,<sp/>rather<sp/>than<sp/>just<sp/>for<sp/>each<sp/>depth,<sp/>only<sp/>six<sp/>were<sp/>trained<sp/>for<sp/>the<sp/>sake<sp/>of<sp/>assessing<sp/>the<sp/>model<sp/>behaviour<sp/>in<sp/>a<sp/>simpler<sp/>and<sp/>more<sp/>understandable<sp/>configuration.</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">####<sp/>2.2.4<sp/>Implementation<sp/>remarks</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">Due<sp/>to<sp/>the<sp/>deterministic<sp/>nature<sp/>of<sp/>the<sp/>first<sp/>stage,<sp/>where<sp/>CTUs<sp/>are<sp/>always<sp/>partitioned<sp/>with<sp/>a<sp/>QT,<sp/>it<sp/>was<sp/>implemented<sp/>together<sp/>with<sp/>the<sp/>second<sp/>stage.<sp/>If<sp/>it<sp/>was<sp/>done<sp/>separately,<sp/>the<sp/>training<sp/>for<sp/>the<sp/>first<sp/>two<sp/>stages<sp/>would<sp/>have<sp/>to<sp/>be<sp/>done<sp/>at<sp/>the<sp/>same<sp/>time.<sp/>Consequently,<sp/>two<sp/>distinct<sp/>optimisers<sp/>would<sp/>need<sp/>to<sp/>be<sp/>employed,<sp/>which<sp/>could<sp/>result<sp/>in<sp/>unpredictable<sp/>training<sp/>behaviour.<sp/>&lt;br&gt;</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">&lt;div<sp/>align=&quot;center&quot;&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;img<sp/>src=&quot;../../imgs/subnet_min_32_1.drawio.png&quot;<sp/>width=300/&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;img<sp/>src=&quot;../../imgs/subnet_min_32_2.drawio.png&quot;<sp/>width=300/&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;p&gt;Fig.<sp/>9:<sp/>32<sp/>minimum<sp/>axis<sp/>size<sp/>sub-networks&lt;/p&gt;</highlight></codeline>
<codeline><highlight class="normal">&lt;/div&gt;</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">When<sp/>implementing<sp/>the<sp/>sub-networks<sp/>on<sp/>code,<sp/>those<sp/>that<sp/>were<sp/>meant<sp/>to<sp/>cater<sp/>for<sp/>varying<sp/>CU<sp/>sizes<sp/>were<sp/>further<sp/>implemented<sp/>separately.<sp/>For<sp/>example,<sp/>in<sp/>the<sp/>case<sp/>of<sp/>the<sp/>sub-network<sp/>utilised<sp/>when<sp/>the<sp/>minimum<sp/>width<sp/>or<sp/>height<sp/>is<sp/>32,<sp/>two<sp/>variants<sp/>of<sp/>the<sp/>first<sp/>two<sp/>layers<sp/>were<sp/>built.<sp/>This<sp/>was<sp/>done<sp/>because<sp/>64x32<sp/>and<sp/>32x32<sp/>CUs<sp/>can<sp/>flow<sp/>across<sp/>this<sp/>block.<sp/>Because<sp/>of<sp/>this,<sp/>the<sp/>first<sp/>two<sp/>layers<sp/>were<sp/>implemented<sp/>separately<sp/>from<sp/>the<sp/>entire<sp/>block.<sp/>Then,<sp/>they<sp/>were<sp/>used<sp/>in<sp/>conjunction<sp/>with<sp/>the<sp/>remaining<sp/>layers<sp/>based<sp/>on<sp/>the<sp/>dimensions<sp/>of<sp/>the<sp/>input<sp/>CU.<sp/>The<sp/>same<sp/>procedures<sp/>were<sp/>followed<sp/>for<sp/>the<sp/>other<sp/>types<sp/>of<sp/>sub-networks.</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">When<sp/>the<sp/>network<sp/>was<sp/>being<sp/>trained,<sp/>some<sp/>of<sp/>the<sp/>RD<sp/>costs<sp/>from<sp/>the<sp/>input<sp/>data<sp/>had<sp/>very<sp/>high<sp/>values.<sp/>Consequently,<sp/>the<sp/>RD<sp/>loss<sp/>function<sp/>value<sp/>skyrocketed,<sp/>resulting<sp/>in<sp/>extremely<sp/>huge<sp/>gradients<sp/>during<sp/>training.<sp/>As<sp/>a<sp/>result,<sp/>the<sp/>maximum<sp/>RD<sp/>cost<sp/>was<sp/>hard<sp/>coded<sp/>at<sp/>$10^{10}$.<sp/>This<sp/>amount<sp/>is<sp/>large<sp/>enough<sp/>to<sp/>be<sp/>more<sp/>than<sp/>the<sp/>best<sp/>partition&apos;s<sp/>RD<sp/>cost<sp/>and<sp/>small<sp/>enough<sp/>to<sp/>address<sp/>this<sp/>issue.<sp/></highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">##<sp/>3.<sp/>Dataset</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">Please<sp/>see<sp/>this<sp/>[page](dataset.md)<sp/>to<sp/>understand<sp/>better<sp/>the<sp/>dataset<sp/>and<sp/>also<sp/>access<sp/>it.<sp/>To<sp/>see<sp/>example<sp/>data<sp/>go<sp/>to<sp/>follow<sp/>[this](exampledatapage.md).</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">##<sp/>4.<sp/>Results</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">Since<sp/>it<sp/>was<sp/>verified<sp/>that<sp/>the<sp/>Rate-Distortion<sp/>Loss.<sp/>$L_{RD}$,<sp/>could<sp/>contribute<sp/>for<sp/>better<sp/>results,<sp/>the<sp/>metrics<sp/>presented<sp/>here<sp/>were<sp/>obtained<sp/>with<sp/>a<sp/>model<sp/>trained<sp/>only<sp/>with<sp/>the<sp/>modified<sp/>cross-entropy<sp/>loss.</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">###<sp/>4.1<sp/>F1-score,<sp/>Recall<sp/>and<sp/>Precision<sp/>with<sp/>test<sp/>data</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">|<sp/>Stage<sp/>|<sp/>F1-Score<sp/>|<sp/>Recall<sp/>|<sp/>Precision<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|-------|----------|--------|-----------|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>Stage<sp/>2<sp/>|<sp/>0.9111<sp/>|<sp/>0.9111<sp/>|<sp/>0.9112<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>Stage<sp/>3<sp/>|<sp/>0.5624<sp/>|<sp/>0.5767<sp/>|<sp/>0.5770<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>Stage<sp/>4<sp/>|<sp/>0.4406<sp/>|<sp/>0.4581<sp/>|<sp/>0.4432<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>Stage<sp/>5<sp/>|<sp/>0.5143<sp/>|<sp/>0.5231<sp/>|<sp/>0.5184<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>Stage<sp/>6<sp/>|<sp/>0.7282<sp/>|<sp/>0.7411<sp/>|<sp/>0.7311<sp/>|</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">Results<sp/>with<sp/>weighted<sp/>average<sp/>for<sp/>F1-score,<sp/>recall<sp/>and<sp/>precision.</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">###<sp/>4.2<sp/>Confusion<sp/>matrices</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">####<sp/>4.2.1<sp/>Stages<sp/>2<sp/>and<sp/>3</highlight></codeline>
<codeline><highlight class="normal">&lt;div<sp/>align=&quot;center&quot;&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;img<sp/>src=&quot;../../imgs/conf_mat_val_stg2.png&quot;<sp/>width=300<sp/>/&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;img<sp/>src=&quot;../../imgs/conf_mat_val_v2_stg3.png&quot;<sp/>width=300<sp/>/&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;p&gt;Fig.<sp/>10:<sp/>Confusion<sp/>matrix<sp/>results<sp/>with<sp/>the<sp/>testing<sp/>data<sp/>in<sp/>stages<sp/>2<sp/>and<sp/>3&lt;/p&gt;</highlight></codeline>
<codeline><highlight class="normal">&lt;/div&gt;</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">####<sp/>4.2.2<sp/>Stages<sp/>4<sp/>and<sp/>5</highlight></codeline>
<codeline><highlight class="normal">&lt;div<sp/>align=&quot;center&quot;&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;img<sp/>src=&quot;../../imgs/conf_mat_val_stg4.png&quot;<sp/>width=300<sp/>/&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;img<sp/>src=&quot;../../imgs/conf_mat_val_stg5.png&quot;<sp/>width=300<sp/>/&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;p&gt;Fig.<sp/>11:<sp/>Confusion<sp/>matrix<sp/>results<sp/>with<sp/>the<sp/>testing<sp/>data<sp/>in<sp/>stages<sp/>4<sp/>and<sp/>5&lt;/p&gt;</highlight></codeline>
<codeline><highlight class="normal">&lt;/div&gt;</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">####<sp/>4.2.3<sp/>Stage<sp/>6</highlight></codeline>
<codeline><highlight class="normal">&lt;div<sp/>align=&quot;center&quot;&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;img<sp/>src=&quot;../../imgs/conf_mat_val_stg6.png&quot;<sp/>width=300<sp/>/&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;p&gt;Fig.<sp/>12:<sp/>Confusion<sp/>matrix<sp/>results<sp/>with<sp/>the<sp/>testing<sp/>data<sp/>in<sp/>stage<sp/>6&lt;/p&gt;</highlight></codeline>
<codeline><highlight class="normal">&lt;/div&gt;</highlight></codeline>
<codeline></codeline>
<codeline></codeline>
<codeline></codeline>
<codeline><highlight class="normal">###<sp/>4.3<sp/>Y-PSNR,<sp/>Complexity<sp/>Reduction<sp/>and<sp/>Bitrate<sp/>with<sp/>test<sp/>data</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">|<sp/>Metric<sp/>|<sp/>VTM-7.0<sp/>|<sp/>VTM-7.0+Model<sp/>|<sp/>Gain<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|-------|----------|--------|-----------|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>Bitrate<sp/>|<sp/>3810.192<sp/>kbps<sp/>|<sp/>4069.392<sp/>kbps<sp/>|<sp/>6.80%<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>Y-PSNR<sp/>|<sp/>35.7927<sp/>dB<sp/><sp/>|<sp/>35.5591<sp/>dB<sp/>|<sp/>-0.65%<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>Complexity<sp/>|<sp/>1792.88<sp/>s<sp/><sp/>|<sp/>1048.95<sp/>s<sp/>|<sp/>-41.49%<sp/>|</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">**These<sp/>results<sp/>were<sp/>obtained<sp/>with<sp/>the<sp/>&quot;medium&quot;<sp/>configuration<sp/>for<sp/>the<sp/>multi-thresholding<sp/>method.**</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">##<sp/>5.<sp/>Relevant<sp/>Folders<sp/>and<sp/>files</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">###<sp/>5.1<sp/>Folders</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">|<sp/>Folder<sp/>|<sp/>Description<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|--------|-------------|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>[dataset](/dataset)<sp/>|<sp/>This<sp/>folder<sp/>contains<sp/>all<sp/>of<sp/>the<sp/>dataset<sp/>and<sp/>all<sp/>of<sp/>the<sp/>data<sp/>that<sp/>was<sp/>processed<sp/>in<sp/>order<sp/>to<sp/>obtain<sp/>it<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>[example_data](/example_data)<sp/>|<sp/>Here<sp/>you<sp/>can<sp/>find<sp/>some<sp/>example<sp/>data<sp/>that<sp/>it<sp/>is<sp/>used<sp/>for<sp/>the<sp/>scripts<sp/>in<sp/>usefull_scripts<sp/>folder|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>[model_coefficients](/model_coefficients)<sp/>|<sp/>The<sp/>last<sp/>coefficient<sp/>obtained<sp/>during<sp/>training,<sp/>as<sp/>well<sp/>as<sp/>the<sp/>best<sp/>one<sp/>in<sp/>terms<sp/>of<sp/>the<sp/>best<sp/>F1-score<sp/>obtained<sp/>in<sp/>testing data<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>[src](/src)<sp/>|<sp/>Source<sp/>code<sp/>with<sp/>the<sp/>implementation<sp/>of<sp/>the<sp/>MSE-CNN<sp/>and<sp/>also<sp/>useful<sp/>code<sp/>and<sp/>examples<sp/>|</highlight></codeline>
<codeline></codeline>
<codeline></codeline>
<codeline></codeline>
<codeline><highlight class="normal">###<sp/>5.2<sp/>Files<sp/>in<sp/>src<sp/>folder</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">|<sp/>Files<sp/>|<sp/>Description<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|--------|-------------|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>constants.py<sp/>|<sp/>Constant<sp/>values<sp/>used<sp/>in<sp/>other<sp/>python<sp/>files<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>custom_dataset.py<sp/>|<sp/>Dataset<sp/>class<sp/>to<sp/>handle<sp/>the<sp/>files<sp/>with<sp/>the<sp/>ground-thruth<sp/>information,<sp/>as<sp/>well<sp/>as<sp/>other<sp/>usefull<sp/>classes<sp/>to<sp/>work<sp/>together<sp/>with<sp/>the<sp/>aforementioned<sp/>class<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>dataset_utils.py<sp/>|<sp/>Functions<sp/>to<sp/>manipulate<sp/>and<sp/>process<sp/>the<sp/>data,<sp/>also<sp/>contains<sp/>functions<sp/>to<sp/>interact<sp/>with<sp/>YUV<sp/>files<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>msecnn.py<sp/>|<sp/>MSE-CNN<sp/>and<sp/>Loss<sp/>Function<sp/>classes<sp/>implementation<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>train_model_utils.py<sp/>|<sp/>Usefull<sp/>functions<sp/>to<sp/>be<sp/>used<sp/>during<sp/>training<sp/>or<sp/>evaluation<sp/>of<sp/>the<sp/>artificial<sp/>neural<sp/>network<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>utils.py<sp/>|<sp/>Other<sp/>functions<sp/>that<sp/>are<sp/>usefull<sp/>not<sp/>directly<sp/>to<sp/>the<sp/>model<sp/>but<sp/>for<sp/>the<sp/>code<sp/>implementation<sp/>itself<sp/>|</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">##<sp/>6.<sp/>Installation<sp/>of<sp/>dependencies</highlight></codeline>
<codeline><highlight class="normal">In<sp/>order<sp/>to<sp/>explore<sp/>this<sp/>project,<sp/>it<sp/>is<sp/>needed<sp/>to<sp/>first<sp/>install<sp/>of<sp/>the<sp/>libraries<sp/>used<sp/>in<sp/>it.</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">###<sp/>Requirements</highlight></codeline>
<codeline><highlight class="normal">For<sp/>this<sp/>please<sp/>follow<sp/>the<sp/>below<sp/>steps:</highlight></codeline>
<codeline><highlight class="normal">1.<sp/>Create<sp/>a<sp/>virtual<sp/>environment<sp/>to<sp/>do<sp/>install<sp/>the<sp/>libraries;<sp/>follow<sp/>this<sp/>[link](https://www.geeksforgeeks.org/creating-python-virtual-environment-windows-linux/)<sp/>in<sp/>case<sp/>you<sp/>don&apos;t<sp/>know<sp/>how<sp/>to<sp/>do<sp/>it;<sp/>you<sp/>possibly<sp/>need<sp/>to<sp/>install<sp/>[pip](https://www.makeuseof.com/tag/install-pip-for-python/),<sp/>if<sp/>you<sp/>don&apos;t<sp/>have<sp/>it<sp/>installed</highlight></codeline>
<codeline><highlight class="normal">2.<sp/>Run<sp/>the<sp/>following<sp/>command:<sp/></highlight></codeline>
<codeline><highlight class="normal">```shell</highlight></codeline>
<codeline><highlight class="normal">pip<sp/>install<sp/>-r<sp/>requirements.txt</highlight></codeline>
<codeline><highlight class="normal">```</highlight></codeline>
<codeline><highlight class="normal">This<sp/>will<sp/>install<sp/>all<sp/>of<sp/>the<sp/>libraries<sp/>references<sp/>in<sp/>the<sp/>requirements.txt<sp/>file.</highlight></codeline>
<codeline><highlight class="normal">1.<sp/>When<sp/>you<sp/>have<sp/>finished<sp/>using<sp/>the<sp/>package<sp/>or<sp/>working<sp/>on<sp/>your<sp/>project,<sp/>you<sp/>can<sp/>deactivate<sp/>the<sp/>virtual<sp/>environment:</highlight></codeline>
<codeline><highlight class="normal">```shell</highlight></codeline>
<codeline><highlight class="normal">deactivate</highlight></codeline>
<codeline><highlight class="normal">```</highlight></codeline>
<codeline><highlight class="normal">This<sp/>command<sp/>exits<sp/>the<sp/>virtual<sp/>environment<sp/>and<sp/>returns<sp/>you<sp/>to<sp/>your<sp/>normal<sp/>command<sp/>prompt.</highlight></codeline>
<codeline><highlight class="normal">1.<sp/>Enjoy!<sp/>:)</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">###<sp/>Package<sp/>Distributions</highlight></codeline>
<codeline><highlight class="normal">1.<sp/>Locate<sp/>the<sp/>`dist`<sp/>folder<sp/>in<sp/>your<sp/>project&apos;s<sp/>root<sp/>directory.<sp/>This<sp/>folder<sp/>contains<sp/>the<sp/>package<sp/>distributions,<sp/>including<sp/>the<sp/>source<sp/>distribution<sp/>(`*.tar.gz`<sp/>file)<sp/>and<sp/>the<sp/>wheel<sp/>distribution<sp/>(`*.whl`<sp/>file).</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">2.<sp/>Install<sp/>the<sp/>package<sp/>using<sp/>one<sp/>of<sp/>the<sp/>following<sp/>methods:</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/>-<sp/>Install<sp/>the<sp/>source<sp/>distribution:</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/>```shell</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/>pip<sp/>install<sp/>dist/msecnn_raulkviana-1.0.tar.gz</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/>```</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/>-<sp/>Install<sp/>the<sp/>wheel<sp/>distribution:</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/>```shell</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/>pip<sp/>install<sp/>dist/msecnn_raulkviana-1.0.whl</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/>```</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">3.<sp/>Once<sp/>the<sp/>package<sp/>is<sp/>installed,<sp/>you<sp/>can<sp/>import<sp/>and<sp/>use<sp/>its<sp/>functionalities<sp/>in<sp/>your<sp/>Python<sp/>code.</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">##<sp/>7.<sp/>Contributions</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">Feel<sp/>free<sp/>to<sp/>contact<sp/>me<sp/>through<sp/>this<sp/>[email](raulviana@ua.pt)<sp/>or<sp/>create<sp/>either<sp/>a<sp/>issue<sp/>or<sp/>pull<sp/>request<sp/>to<sp/>contribute<sp/>to<sp/>this<sp/>project<sp/>^^.</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">##<sp/>8.<sp/>License</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">This<sp/>project<sp/>license<sp/>is<sp/>under<sp/>the<sp/>[MIT<sp/>License](LICENSE).</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">##<sp/>9.<sp/>TODO</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">|Task|<sp/>Description|<sp/>Status<sp/>(d<sp/>-<sp/>doing,<sp/>w<sp/>-<sp/>waiting,<sp/>f-<sp/>finished)|</highlight></codeline>
<codeline><highlight class="normal">|-----|-----|-----|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>Implement<sp/>code<sp/>to<sp/>test<sp/>functions|<sp/>Use<sp/>a<sp/>library,<sp/>such<sp/>as<sp/>Pytest,<sp/>to<sp/>test<sp/>some<sp/>functions<sp/>from<sp/>the<sp/>many<sp/>modules<sp/>developed<sp/>|<sp/>w<sp/>|</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">##<sp/>10.<sp/>References</highlight></codeline>
<codeline><highlight class="normal">[1]<sp/>T.<sp/>Li,<sp/>M.<sp/>Xu,<sp/>R.<sp/>Tang,<sp/>Y.<sp/>Chen,<sp/>and<sp/>Q.<sp/>Xing,<sp/>[“DeepQTMT:<sp/>A<sp/>Deep<sp/>Learning<sp/>Approach<sp/>for<sp/>Fast<sp/>QTMT-Based<sp/>CU<sp/>Partition<sp/>of<sp/>Intra-Mode<sp/>VVC,”](https://arxiv.org/abs/2006.13125)<sp/>IEEE<sp/>Transactions<sp/>on<sp/>Image<sp/>Processing,<sp/>vol.<sp/>30,<sp/>pp.<sp/>5377–5390,<sp/>2021,<sp/>doi:<sp/>10.1109/tip.2021.3083447.</highlight></codeline>
<codeline><highlight class="normal">[2]<sp/>R.<sp/>K.<sp/>Viana,<sp/>“Deep<sp/>learning<sp/>architecture<sp/>for<sp/>fast<sp/>intra-mode<sp/>CUs<sp/>partitioning<sp/>in<sp/>VVC,”<sp/>Universidade<sp/>de<sp/>Aveiro,<sp/>Nov.<sp/>2022.</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">&lt;div<sp/>align=&quot;center&quot;&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;img<sp/>src=&quot;../../imgs/funny_memes_about_this_work/72rukf.gif&quot;<sp/>width=450<sp/>/&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&lt;p&gt;:)&lt;/p&gt;</highlight></codeline>
<codeline><highlight class="normal">&lt;/div&gt;</highlight></codeline>
<codeline></codeline>
<codeline></codeline>
<codeline></codeline>
    </programlisting>
    <location file="pages_doxygen/mainpage.md"/>
  </compounddef>
</doxygen>
